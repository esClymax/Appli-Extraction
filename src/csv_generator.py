"""
G√©n√©rateur de fichiers CSV
"""

import pandas as pd
import io
import os
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime
from .processors import DataFrameProcessor, DataFrameCombiner
from .extractors import MultiMethodExtractor
from .utils import FileNameSanitizer
from config import DEFAULT_CLEANING_RULES


class CSVGenerator:
    """G√©n√©rateur de fichiers CSV individuels et consolid√©s"""
    
    def __init__(self, extraction_config):
        self.config = extraction_config
        self.extractor = MultiMethodExtractor()
        self.processor = DataFrameProcessor(extraction_config.cleaning_rules)
        os.makedirs(extraction_config.output_directory, exist_ok=True)
    
    def generate_individual_csv(self, pdf_filename: str) -> Tuple[Optional[str], Dict, int, Optional[bytes], Optional[pd.DataFrame]]:
        """
        G√©n√®re un fichier CSV pour un PDF individuel
        
        Args:
            pdf_filename: Nom du fichier PDF
            
        Returns:
            Tuple (chemin_csv, r√©sultats_traitement, succ√®s_count, donn√©es_csv, dataframe_fusionn√©)
        """
        print(f"üü¢ D√©but du traitement de {len(self.config.page_ranges_dict)} cat√©gories")
        print(f"üìÅ R√©pertoire de sortie: {self.config.output_directory}")
        
        # Pr√©parer le nom du fichier CSV
        base_name = os.path.splitext(pdf_filename)[0]
        safe_base_name = FileNameSanitizer.sanitize_filename(base_name)
        csv_filename = f"{safe_base_name}.csv"
        csv_filepath = os.path.join(self.config.output_directory, csv_filename)
        
        # Traiter chaque cat√©gorie
        all_dataframes = []
        processing_results = {}
        success_count = 0
        
        for category_name, page_ranges in self.config.page_ranges_dict.items():
            result = self._process_category(category_name, page_ranges, pdf_filename)
            
            if result['success']:
                all_dataframes.append(result['dataframe'])
                success_count += 1
            
            processing_results[category_name] = result
        
        # G√©n√©rer le CSV final
        if all_dataframes:
            return self._create_csv_file(all_dataframes, csv_filepath, csv_filename, 
                                       success_count, processing_results)
        else:
            print("‚ùå Aucune donn√©e √† √©crire dans le fichier CSV")
            return None, processing_results, 0, None, None
    
    def _process_category(self, category_name: str, page_ranges: List[str], 
                         pdf_filename: str) -> Dict[str, Any]:
        """
        Traite une cat√©gorie sp√©cifique
        
        Args:
            category_name: Nom de la cat√©gorie
            page_ranges: Plages de pages
            pdf_filename: Nom du fichier PDF
            
        Returns:
            Dictionnaire avec les r√©sultats du traitement
        """
        print(f"\nüîç Traitement de la cat√©gorie: '{category_name}'")
        
        try:
            # Extraire les tableaux
            tables = self.extractor.extract_with_all_methods(
                self.config.pdf_path, page_ranges, category_name, 
                self.config.extraction_methods
            )
            
            if not tables:
                return {
                    'success': False,
                    'error': 'Aucun tableau extrait',
                    'category_label': category_name,
                    'rows': 0,
                    'cols': 0
                }
            
            # Combiner les tableaux
            combined_df = DataFrameCombiner.combine_tables(tables)
            
            # Traiter le DataFrame
            processed_df = self.processor.process_dataframe(
                combined_df, category_name, pdf_filename
            )
            
            if processed_df is None or processed_df.empty:
                return {
                    'success': False,
                    'error': 'DataFrame vide apr√®s traitement',
                    'category_label': category_name,
                    'rows': 0,
                    'cols': 0
                }
            
            print(f"    ‚úÖ Pr√©par√©: {category_name} ({processed_df.shape[0]} lignes, {processed_df.shape[1]} colonnes)")
            
            return {
                'success': True,
                'dataframe': processed_df,
                'category_label': category_name,
                'rows': len(processed_df),
                'cols': len(processed_df.columns)
            }
            
        except Exception as e:
            print(f"    ‚ùå Erreur cat√©gorie '{category_name}': {e}")
            return {
                'success': False,
                'error': str(e),
                'category_label': category_name,
                'rows': 0,
                'cols': 0
            }
    
    def _create_csv_file(self, dataframes: List[pd.DataFrame], csv_filepath: str,
                        csv_filename: str, success_count: int, 
                        processing_results: Dict) -> Tuple[str, Dict, int, bytes, pd.DataFrame]:
        """
        Cr√©e le fichier CSV final
        
        Args:
            dataframes: Liste des DataFrames √† combiner
            csv_filepath: Chemin du fichier CSV
            csv_filename: Nom du fichier CSV
            success_count: Nombre de cat√©gories trait√©es avec succ√®s
            processing_results: R√©sultats du traitement
            
        Returns:
            Tuple avec les informations du fichier cr√©√©
        """
        try:
            # Fusionner tous les DataFrames
            merged_df = DataFrameCombiner.concatenate_all_dataframes(dataframes)
            
            # Cr√©er le contenu CSV
            csv_buffer = io.StringIO()
            merged_df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
            csv_data = csv_buffer.getvalue().encode('utf-8-sig')
            
            # Sauvegarder le fichier
            with open(csv_filepath, 'w', encoding='utf-8-sig', newline='') as f:
                f.write(csv_buffer.getvalue())
            
            print(f"\n‚úÖ Fichier CSV cr√©√© avec succ√®s: {csv_filename}")
            print(f"üìä {len(merged_df)} lignes totales, {len(merged_df.columns)} colonnes")
            print(f"\nüìä R√âSUM√â:")
            print(f"   ‚úÖ {success_count}/{len(self.config.page_ranges_dict)} cat√©gories trait√©es avec succ√®s")
            print(f"   üìÅ Fichier CSV: {csv_filepath}")
            
            return csv_filepath, processing_results, success_count, csv_data, merged_df
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la cr√©ation du fichier CSV: {e}")
            return None, processing_results, 0, None, None


class GlobalCSVGenerator:
    """G√©n√©rateur de CSV global consolid√©"""
    
    @staticmethod
    def create_global_csv(all_results: Dict[str, Dict]) -> Optional[bytes]:
        """
        Cr√©e un CSV global consolidant toutes les donn√©es de tous les PDF
        
        Args:
            all_results: Dictionnaire des r√©sultats de tous les PDF
            
        Returns:
            Donn√©es du CSV global ou None
        """
        print(f"\nüåê Cr√©ation du CSV global consolid√©...")
        
        all_dataframes = []
        
        for pdf_name, result in all_results.items():
            if result.get('merged_dataframe') is not None:
                df = result['merged_dataframe'].copy()
                all_dataframes.append(df)
                print(f"   üìÑ {pdf_name}: {len(df)} lignes ajout√©es")
        
        if not all_dataframes:
            print("   ‚ùå Aucune donn√©e √† consolider")
            return None
        
        try:
            # Concat√©ner tous les DataFrames
            global_df = DataFrameCombiner.concatenate_all_dataframes(all_dataframes)
            
            # Cr√©er le CSV global
            csv_buffer = io.StringIO()
            global_df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
            global_csv_data = csv_buffer.getvalue().encode('utf-8-sig')
            
            print(f"   ‚úÖ CSV global cr√©√©: {len(global_df)} lignes totales, {len(global_df.columns)} colonnes")
            
            return global_csv_data
            
        except Exception as e:
            print(f"   ‚ùå Erreur lors de la cr√©ation du CSV global: {e}")
            return None
    
    @staticmethod
    def get_global_csv_filename() -> str:
        """
        G√©n√®re un nom de fichier pour le CSV global
        
        Returns:
            Nom de fichier avec timestamp
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        return f"extraction_globale_consolidee_{timestamp}.csv"


class ExtractionConfig:
    """Configuration pour l'extraction"""
    
    def __init__(self, pdf_path: str, page_ranges_dict: Dict[str, List[str]], 
                 output_directory: str = "extracted_categories",
                 extraction_methods: List[str] = None,
                 cleaning_rules: Dict[str, Any] = None,
                 column_mapping: Dict[str, str] = None,
                 filters: Dict[str, Any] = None):
        
        self.pdf_path = pdf_path
        self.page_ranges_dict = page_ranges_dict
        self.output_directory = output_directory
        self.extraction_methods = extraction_methods or ["pdfplumber"]
        self.cleaning_rules = cleaning_rules or DEFAULT_CLEANING_RULES.copy()
        self.column_mapping = column_mapping or {}
        self.filters = filters or {}
